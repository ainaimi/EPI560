---
title: "Propensity Score Diagnostics: Extended Example"
author: "Ashley I Naimi"
date: "`r paste0('Spring ', 2024)`" #format(Sys.Date(), '%Y')
urlcolor: blue
link-citations: yes
output: pdf_document
---

# Simulating Data

Let's gain some intuition behind the idea of the propensity score, and whether it can tell us anything about exchangeability.

We'll start with some simple simulated data, so that we know the true relations, effects, and confounders:

```{r tidy = F, warning = F, messge = F}

pacman::p_load(
  here,         
  tidyverse,
  mvtnorm,
  spatstat, 
  gridExtra
  )

thm <- theme_classic() +
  theme(
    legend.position = "top",
    legend.background = element_rect(fill = "transparent", colour = NA),
    legend.key = element_rect(fill = "transparent", colour = NA)
  )
theme_set(thm)

expit <- function(x){1/(1+exp(-x))}
sample_size <- 100000

set.seed(234)

c <- mvtnorm::rmvnorm(n = sample_size, mean = rep(0, 4), sigma = diag(4))

# true ps model
pi_x <- expit(-2 + log(2)*c[,1] + log(2)*c[,2] + log(2)*c[,3] + log(4)*c[,4])

x <- rbinom(n = sample_size, size = 1, prob = pi_x)

mean(x)

# true outcome model
y <- rnorm(n = sample_size, mean = 120 + 3.5*x + 2*c[,1] + 2*c[,2] + 2*c[,3] + 4*c[,4], sd = 1)

ggplot() + 
  geom_histogram(aes(y)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0))


## the observed data: NOTE WE'RE MISSING THE STRONGEST CONFOUNDER!!
dat_ <- data.frame(y, x, c[,1:3])

names(dat_) <- c("y","x", paste0("c", 1:3))

head(dat_)
```

# Propensity Score Fitting

Let's now use these data to fit a propensity score model:

```{r tidy = F, warning = F, messge = F}

propensity_score <- glm(x ~ c1 + c2 + c3, data = dat_, 
                        family = binomial("logit"))$fitted.values
```

## Propensity Score Overlap

```{r tidy = F, warning = F, messge = F}
# ps overlap plot

plot_dat <- data.frame(Exposure = factor(dat_$x), PropensityScore = propensity_score)

ggplot(plot_dat) + 
  geom_density(aes(x = PropensityScore, group = Exposure, fill = Exposure), alpha = .5) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0))

```

PS overlap is not terrible. Let's look at stabilized weights:

## Stabilized Weight Distribution

```{r, warning = F, messge = F}

sw <- (mean(dat_$x)/propensity_score)*dat_$x + 
  ((1 - mean(dat_$x))/(1 - propensity_score))*(1 - dat_$x)

summary(sw)

```

Distribution of stabilized weights look good!

## Covariate "Balance" Across Exposure (via logit regression)

Let's try even more diagnostics of the propensity score to see if we've achieved "balance":

We can look at odds ratios for each confounder-exposure association:

```{r, warning = F, messge = F}

# pre - balance

summary(glm(x ~ c1 + c2 + c3, data = dat_, family = binomial("logit")))$coefficients

# note the difference

```

Now let's get weighted odds ratios for each confounder-exposure association:

```{r, warning = F, messge = F}

# post - balance

dat_$sw <- sw

summary(glm(x ~ c1 + c2 + c3, data = dat_, weights = sw, family = binomial("logit")))$coefficients

# note the similarity!

```

## Unweighted and Weighted eCDFs

Let's look at the cumulative distribution functions for each confounder stratified by the exposure:

```{r, tidy = F, warning = F, messge = F}

p1 <- ggplot(dat_, aes(c1, colour = factor(x))) + stat_ecdf()
p2 <- ggplot(dat_, aes(c2, colour = factor(x))) + stat_ecdf()
p3 <- ggplot(dat_, aes(c3, colour = factor(x))) + stat_ecdf()

grid.arrange(p1,p2,p3, nrow = 1)

```

Now let's look at the same CDFs for each confounder, but weighted by sw:

```{r, tidy = F, include = F, warning = F, messge = F}

library(spatstat)


#' Compute empirical cumulative distribution
#'
#' The empirical cumulative distribution function (ECDF) provides an alternative
#' visualisation of distribution. Compared to other visualisations that rely on
#' density (like [geom_histogram()]), the ECDF doesn't require any
#' tuning parameters and handles both continuous and categorical variables.
#' The downside is that it requires more training to accurately interpret,
#' and the underlying visual tasks are somewhat more challenging.
#'
#' @inheritParams layer
#' @inheritParams geom_point
#' @param na.rm If `FALSE` (the default), removes missing values with
#'    a warning.  If `TRUE` silently removes missing values.
#' @param n if NULL, do not interpolate. If not NULL, this is the number
#'   of points to interpolate with.
#' @param pad If `TRUE`, pad the ecdf with additional points (-Inf, 0)
#'   and (Inf, 1)
#' @section Computed variables:
#' \describe{
#'   \item{x}{x in data}
#'   \item{y}{cumulative density corresponding x}
#' }
#' @export
#' @examples
#' df <- data.frame(
#'   x = c(rnorm(100, 0, 3), rnorm(100, 0, 10)),
#'   g = gl(2, 100)
#' )
#' ggplot(df, aes(x)) + stat_ecdf(geom = "step")
#'
#' # Don't go to positive/negative infinity
#' ggplot(df, aes(x)) + stat_ecdf(geom = "step", pad = FALSE)
#'
#' # Multiple ECDFs
#' ggplot(df, aes(x, colour = g)) + stat_ecdf()
stat_ecdf <- function(mapping = NULL, data = NULL,
                      geom = "step", position = "identity",
                      weight =  NULL, 
                      ...,
                      n = NULL,
                      pad = TRUE,
                      na.rm = FALSE,
                      show.legend = NA,
                      inherit.aes = TRUE) {
  layer(
    data = data,
    mapping = mapping,
    stat = StatEcdf,
    geom = geom,
    position = position,
    show.legend = show.legend,
    inherit.aes = inherit.aes,
    params = list(
      n = n,
      pad = pad,
      na.rm = na.rm,
      weight = weight,
      ...
    )
  )
}


#' @rdname ggplot2-ggproto
#' @format NULL
#' @usage NULL
#' @export
#' 

StatEcdf <- ggproto("StatEcdf", Stat,
                    compute_group = function(data, scales, weight, n = NULL, pad = TRUE) {
                      # If n is NULL, use raw values; otherwise interpolate
                      if (is.null(n)) {
                        x <- unique(data$x)
                      } else {
                        x <- seq(min(data$x), max(data$x), length.out = n)
                      }
                      
                      if (pad) {
                        x <- c(-Inf, x, Inf)
                      }
                      y <- ewcdf(data$x, weights=data$weight/sum(data$weight))(x)
                      
                      data.frame(x = x, y = y)
                    },
                    
                    default_aes = aes(y = stat(y)),
                    
                    required_aes = c("x")
)

```

```{r, tidy = F, warning = F, message = F}

## note: we need to modify the stat_ecdf function to include weights.
## https://github.com/NicolasWoloszko/stat_ecdf_weighted
p1 <- ggplot(dat_, aes(c1, colour = factor(x), weight = sw)) + stat_ecdf()
p2 <- ggplot(dat_, aes(c2, colour = factor(x), weight = sw)) + stat_ecdf()
p3 <- ggplot(dat_, aes(c3, colour = factor(x), weight = sw)) + stat_ecdf()

grid.arrange(p1,p2,p3, nrow = 1)

```


# Despite Balance, Still Bias

Clearly, all these metrics suggest to us that there is good covariate balance across the exposed and unexposed group when we weight the analysis. This is true, even though we've failed to include an important confounder in our propensity score model. 

What happens when we conduct a weighted analysis using this mis-specified propensity score model?:

```{r, warning = F, messge = F}

mod_sw <- lm(y ~ x, weights = sw, data = dat_)

summary(mod_sw)$coefficients # let's ignore SE estimation

```

Note that in the simulation code above, we defined the true effect of $X$ on $Y$ to be 3.5. But our weighted analysis suggests this effect is actually `r round(coef(mod_sw)[2], 2)`, which is nowhere near the true effect. This is entirely because we left out $C_4$ from our propensity score model, which was defined as a strong confounder in the simulation.

This example should provide you with some insight as to why propensity score overlap, balance, and other metrics defined on the basis of the propensity score say nothing about exchangeability.

# Correctly Specified PS Model

To confirm that the problem is, in fact, due to the exclusion of $C_4$, let's fit a weighted outcome model with the correct PS:

```{r, tidy = F, warning = F, messge = F}

dat_ <- data.frame(y, x, c[,1:4])

names(dat_) <- c("y","x", paste0("c", 1:4))

head(dat_)

propensity_score <- glm(x ~ c1 + c2 + c3 + c4, data = dat_, 
                        family = binomial("logit"))$fitted.values

# ps overlap plot
plot_dat <- data.frame(Exposure = factor(dat_$x), PropensityScore = propensity_score)

ggplot(plot_dat) + 
  geom_density(aes(x = PropensityScore, group = Exposure, fill = Exposure), alpha = .5) +
  scale_x_continuous(expand = c(0,0)) +
  scale_y_continuous(expand = c(0,0))

dat_$sw <- (mean(dat_$x)/propensity_score)*dat_$x + 
  ((1 - mean(dat_$x))/(1 - propensity_score))*(1 - dat_$x)

summary(dat_$sw)

# weighted outcome model:

mod_sw <- lm(y ~ x, weights = sw, data = dat_)

summary(mod_sw)$coefficients # let's ignore SE estimation

```